#app.py

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from prophet import Prophet
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
import chardet
import io
import kaleido
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Table, TableStyle, Spacer, Image
from reportlab.lib import colors
from reportlab.lib.styles import getSampleStyleSheet
import tempfile
from prophet import Prophet
from statsmodels.tsa.arima.model import ARIMA
from metrics import mean_absolute_error, root_mean_squared_error, mean_absolute_percentage_error

from validation import validate_columns_and_values
from cleaning import clean_data
from feature_engineering import feature_engineering
from forecasting import train_prophet_model, train_arima_model, train_sarima_model, train_xgb_model, prepare_dataset, generate_forecast, auto_detect_columns, get_train_test_split
from pdf_gen import generate_pdf_report

# ---- Streamlit App ----
st.set_page_config(page_title="Forecast Dashboard", layout="wide")
st.title("ðŸ“ˆ Procode Modeling Platform")
st.sidebar.title("Navigation")
section = st.sidebar.radio("Go to", [
    "Upload", "Raw Data", "Cleaned Data", "Feature Engineered Data",
    "Forecast Table", "Forecast Chart", "YoY Growth", "Summary Dashboard",
    "Model Explainability",
    "Advanced Diagnostics",  
    "Download Reports"
])



st.sidebar.header("Forecast Settings")
model_choice = st.sidebar.selectbox(
    "Select Model", ["Auto (Best)", "Prophet", "ARIMA", "SARIMA", "XGBoost"], index=0
)

# Prophet parameters (always define)
seasonality_mode = st.sidebar.selectbox("Seasonality Mode", ["additive", "multiplicative"], index=0)
changepoint_prior_scale = st.sidebar.slider("Changepoint Prior Scale", 0.001, 0.5, 0.05)

# ARIMA parameters (always define)
arima_p = st.sidebar.number_input("ARIMA p (AR)", min_value=0, max_value=5, value=1)
arima_d = st.sidebar.number_input("ARIMA d (I)", min_value=0, max_value=2, value=1)
arima_q = st.sidebar.number_input("ARIMA q (MA)", min_value=0, max_value=5, value=1)

# SARIMA parameters (always define)
sarima_p = st.sidebar.number_input("SARIMA p (AR)", min_value=0, max_value=5, value=1)
sarima_d = st.sidebar.number_input("SARIMA d (I)", min_value=0, max_value=2, value=1)
sarima_q = st.sidebar.number_input("SARIMA q (MA)", min_value=0, max_value=5, value=1)
sarima_P = st.sidebar.number_input("SARIMA P (seasonal AR)", min_value=0, max_value=5, value=1)
sarima_D = st.sidebar.number_input("SARIMA D (seasonal I)", min_value=0, max_value=2, value=1)
sarima_Q = st.sidebar.number_input("SARIMA Q (seasonal MA)", min_value=0, max_value=5, value=1)
sarima_s = st.sidebar.number_input("SARIMA s (seasonal period)", min_value=1, max_value=365, value=12)

# XGBoost info (does not need inputs)
st.sidebar.markdown("XGBoost does not require additional parameters for demo. It uses lags and date parts.")

if 'ran_forecast' not in st.session_state:
    st.session_state["ran_forecast"] = False

if section == "Upload":
    uploaded_file = st.file_uploader("Upload your dataset (CSV or Excel)", type=["csv", "xlsx"])

    if uploaded_file:
        if uploaded_file.name.endswith('.csv'):
            raw_bytes = uploaded_file.read()
            encoding = chardet.detect(raw_bytes)['encoding']
            uploaded_file.seek(0)
            data = pd.read_csv(uploaded_file, encoding=encoding)
        else:
            data = pd.read_excel(uploaded_file)

        st.session_state["raw_data"] = data.copy()

        # Basic cleaning
        cleaned_data = data.drop_duplicates().copy()
        for col in cleaned_data.select_dtypes(include='object').columns:
            cleaned_data[col] = cleaned_data[col].replace(["Not Available", "NULL", "Missing", "Unknown", " "], np.nan)
        for col in cleaned_data.columns:
            if cleaned_data[col].isnull().sum() > 0:
                if cleaned_data[col].dtype in ['float64', 'int64']:
                    cleaned_data[col].fillna(cleaned_data[col].median(), inplace=True)
                elif pd.api.types.is_datetime64_any_dtype(cleaned_data[col]):
                    cleaned_data[col].fillna(cleaned_data[col].mode()[0], inplace=True)
                elif cleaned_data[col].dtype == 'object':
                    cleaned_data[col].fillna("Unknown", inplace=True)
        st.session_state["cleaned_data"] = cleaned_data.copy()

        # Feature engineering
        fe_data = cleaned_data.copy()
        # -- Validation for date and numeric columns --
        # -- Validation for date and numeric columns --
        date_cols = [col for col in fe_data.columns if pd.api.types.is_datetime64_any_dtype(fe_data[col]) or 'date' in col.lower()]
        num_cols = fe_data.select_dtypes(include=np.number).columns

        if len(date_cols) == 0:
            st.error("No date/datetime columns found. Please upload a dataset with at least one date or datetime column.")
            st.stop()

        if len(num_cols) == 0:
            st.error("No numeric columns found. Please upload a dataset with at least one numeric target column.")
            st.stop()

        # For early validation, check ALL date columns for nulls/dupes (summarized)
        if fe_data[date_cols].isnull().any().any():
            st.warning(f"Null values found in one or more date columns. These rows will be dropped.")
            fe_data = fe_data.dropna(subset=date_cols)

        if fe_data[date_cols].duplicated().any().any():
            st.warning(f"Duplicate dates found in one or more date columns. They will be aggregated for forecasting.")


        for col in date_cols:
            fe_data[col] = pd.to_datetime(fe_data[col], errors='coerce')
            fe_data[f"{col}_year"] = fe_data[col].dt.year
            fe_data[f"{col}_month"] = fe_data[col].dt.month
            fe_data[f"{col}_day"] = fe_data[col].dt.day
            fe_data[f"{col}_dayofweek"] = fe_data[col].dt.dayofweek
        st.session_state["fe_data"] = fe_data.copy()

        st.success("Data uploaded and processed. Please proceed to individual sections for detailed view or run forecast.")

        st.subheader("ðŸ“„ Raw Data Preview")
        st.dataframe(data.head())

        st.subheader("ðŸ§¼ Cleaned Data Preview")
        st.dataframe(cleaned_data.head())

        st.subheader("ðŸ› ï¸ Feature Engineered Data Preview")
        st.dataframe(fe_data.head())

        # Auto detect ds and y columns
        auto_date_col, auto_target_col = auto_detect_columns(fe_data)

        st.write("### Select Columns for Forecasting")
        date_col = st.selectbox("Select Date Column (ds)", fe_data.columns, index=fe_data.columns.get_loc(auto_date_col))
        target_col = st.selectbox("Select Target Column (y)", fe_data.select_dtypes(include=np.number).columns, index=list(fe_data.select_dtypes(include=np.number).columns).index(auto_target_col))

        # --- Save to session for later use ---
        st.session_state['date_col'] = date_col
        st.session_state['target_col'] = target_col
        st.session_state['fe_data'] = fe_data

        if st.button("Run Forecast"):
            forecast_data = prepare_dataset(fe_data, date_col, target_col)
            selected_model = model_choice
            forecast = None  # Initialize
            model = None     # Initialize

            if selected_model == "Auto (Best)":
                st.info("Auto-selecting best model using last 30 points as test set...")
                with st.spinner("Comparing models, please wait..."):
                    train, test = get_train_test_split(forecast_data, test_size=30)
                    models_to_try = [
                        ("Prophet", lambda: train_prophet_model(
                            train, 
                            seasonality_mode=seasonality_mode, 
                            changepoint_prior_scale=changepoint_prior_scale, 
                            periods=len(test), 
                            return_model=True)),
                        ("ARIMA", lambda: train_arima_model(
                            train, 
                            order=(arima_p, arima_d, arima_q), 
                            forecast_periods=len(test), 
                            return_model=True)),
                        ("SARIMA", lambda: train_sarima_model(
                            train, 
                            order=(sarima_p, sarima_d, sarima_q), 
                            seasonal_order=(sarima_P, sarima_D, sarima_Q, sarima_s), 
                            forecast_periods=len(test), 
                            return_model=True)),
                        ("XGBoost", lambda: train_xgb_model(
                            train, 
                            forecast_periods=len(test), 
                            return_model=True))
                    ]
                    best_model_name = None
                    best_rmse = np.inf
                    best_model_obj = None
                    best_forecast = None
                    model_results = []
                    for model_name, model_func in models_to_try:
                        try:
                            fc, m_obj = model_func()
                            y_true = test['y'].values
                            if fc.shape[0] > len(y_true):
                                y_pred = fc['yhat'].values[-len(y_true):]
                            else:
                                y_pred = fc['yhat'].values
                            rmse = root_mean_squared_error(y_true, y_pred)
                            model_results.append((model_name, rmse, fc))
                            if rmse < best_rmse:
                                best_rmse = rmse
                                best_model_name = model_name
                                best_model_obj = m_obj
                                best_forecast = fc
                        except Exception as e:
                            st.warning(f"Model {model_name} failed: {e}")

                    # Display comparison table
                    st.subheader("Model RMSE Comparison")
                    st.table({name: round(rmse, 2) for name, rmse, _ in model_results})
                    st.success(f"Best model: {best_model_name} (RMSE={best_rmse:.2f}). Running on full dataset...")

        # Use best model on FULL data
                with st.spinner(f"Generating final forecast with {best_model_name}..."):
                    forecast, model = None, None
                    if best_model_name == "Prophet":
                        forecast, model = train_prophet_model(
                            forecast_data, 
                            seasonality_mode=seasonality_mode, 
                            changepoint_prior_scale=changepoint_prior_scale, 
                            periods=365, 
                            return_model=True)
                    elif best_model_name == "ARIMA":
                        forecast, model = train_arima_model(
                            forecast_data, 
                            order=(arima_p, arima_d, arima_q), 
                            forecast_periods=365, 
                            return_model=True)
                    elif best_model_name == "SARIMA":
                        forecast, model = train_sarima_model(
                            forecast_data, 
                            order=(sarima_p, sarima_d, sarima_q), 
                            seasonal_order=(sarima_P, sarima_D, sarima_Q, sarima_s), 
                            forecast_periods=365, 
                            return_model=True)
                    elif best_model_name == "XGBoost":
                        forecast, model = train_xgb_model(
                            forecast_data, 
                            forecast_periods=365, 
                            return_model=True)
                    selected_model = best_model_name

            else:
                with st.spinner(f"Running {selected_model} model..."):
                    if selected_model == "Prophet":
                        forecast, model = train_prophet_model(
                            forecast_data,
                            seasonality_mode=seasonality_mode,
                            changepoint_prior_scale=changepoint_prior_scale,
                            periods=365,
                            return_model=True
                        )
                    elif selected_model == "ARIMA":
                        order = (arima_p, arima_d, arima_q)
                        forecast, model = train_arima_model(forecast_data, order=order, forecast_periods=365, return_model=True)
                    elif selected_model == "SARIMA":
                        order = (sarima_p, sarima_d, sarima_q)
                        seasonal_order = (sarima_P, sarima_D, sarima_Q, sarima_s)
                        forecast, model = train_sarima_model(forecast_data, order=order, seasonal_order=seasonal_order, forecast_periods=365, return_model=True)
                    elif selected_model == "XGBoost":
                        forecast, model = train_xgb_model(forecast_data, forecast_periods=365, return_model=True)

            st.session_state["forecast"] = forecast
            st.session_state["ran_forecast"] = True
            st.session_state["date_col"] = date_col
            st.session_state["target_col"] = target_col
            st.session_state["selected_model"] = selected_model
            st.session_state["model"] = model

            if forecast is not None:
                st.subheader(f"Forecast Table ({selected_model})")
                st.dataframe(forecast[["ds", "yhat", "yhat_lower", "yhat_upper"]])

                st.subheader(f"Forecast Chart ({selected_model})")
                fig = px.line(forecast, x="ds", y="yhat", title=f"Forecasted Values for {target_col} ({selected_model})")
                fig.add_scatter(x=forecast["ds"], y=forecast["yhat_upper"], mode='lines', name='Upper Bound')
                fig.add_scatter(x=forecast["ds"], y=forecast["yhat_lower"], mode='lines', name='Lower Bound')
                st.plotly_chart(fig, use_container_width=True)

                st.subheader(f"Year-over-Year Growth ({selected_model})")
                forecast["year"] = forecast["ds"].dt.year
                yearly = forecast.groupby("year")["yhat"].sum().reset_index()
                yearly["YoY Growth %"] = yearly["yhat"].pct_change() * 100
                fig2 = px.bar(yearly, x="year", y="YoY Growth %", title=f"YoY Forecast Growth % for {target_col} ({selected_model})")
                st.plotly_chart(fig2, use_container_width=True)

                st.markdown("---")
                st.info(f"âœ… Forecast complete using **{selected_model}**! Please visit the navigation panel for individual graph analysis.")
            else:
                st.error("Forecasting failed for all models. Please check your data or model settings.")


if section == "Raw Data" and "raw_data" in st.session_state:
    st.subheader("ðŸ“„ Raw Data")
    st.dataframe(st.session_state["raw_data"].head())

if section == "Cleaned Data" and "cleaned_data" in st.session_state:
    st.subheader("ðŸ§¼ Cleaned Data")
    st.dataframe(st.session_state["cleaned_data"].head())

if section == "Feature Engineered Data" and "fe_data" in st.session_state:
    st.subheader("ðŸ› ï¸ Feature Engineered Data")
    st.write("Feature engineered data includes additional columns like year, month, day, and day of week extracted from date columns to help improve forecasting accuracy. These features help the model learn seasonal and periodic patterns that occur across time.")
    st.dataframe(st.session_state["fe_data"].head())

if section in ["Forecast Table", "Forecast Chart", "YoY Growth", "Summary Dashboard", "Download Reports"] and not st.session_state.get("ran_forecast"):
    st.warning("Please upload data and run a forecast first.")

if section == "Forecast Table" and st.session_state.get("ran_forecast"):
    forecast = st.session_state["forecast"]
    st.subheader("ðŸ“‹ Forecast Table")
    st.write("This table provides numerical forecast results.\n\nEach row contains the predicted value (\"yhat\") for a specific date, along with the lower and upper bounds of the confidence interval (\"yhat_lower\" and \"yhat_upper\"). This helps you understand both the expected values and potential range of fluctuation.")
    st.dataframe(forecast[["ds", "yhat", "yhat_lower", "yhat_upper"]])

if section == "Forecast Chart" and st.session_state.get("ran_forecast"):
    forecast = st.session_state["forecast"]
    st.subheader("ðŸ“ˆ Forecast Visualization")
    model_used = st.session_state.get("selected_model", "Prophet")
    st.info(f"Model Used: {model_used}")
    st.write("Visualize forecasted values over time with options to show trend lines, confidence intervals, and time-based aggregation.")

    show_trend = st.checkbox("Show Trend Line", True)
    show_bounds = st.checkbox("Show Confidence Interval", True)
    aggregate_option = st.selectbox("Aggregate Forecast", ["None", "Monthly", "Weekly", "Quarterly"], index=0)

    fig = go.Figure()

    if aggregate_option != "None":
        forecast_copy = forecast.copy()

        if aggregate_option == "Monthly":
            forecast_copy["period"] = forecast_copy["ds"].dt.to_period("M").astype(str)
        elif aggregate_option == "Weekly":
            forecast_copy["period"] = forecast_copy["ds"].dt.to_period("W").astype(str)
        elif aggregate_option == "Quarterly":
            forecast_copy["period"] = forecast_copy["ds"].dt.to_period("Q").astype(str)

        agg_df = forecast_copy.groupby("period")["yhat"].sum().reset_index()
        fig.add_trace(go.Scatter(x=agg_df["period"], y=agg_df["yhat"], mode='lines+markers', name=f'{aggregate_option} Forecast'))
        fig.update_layout(title=f"{aggregate_option} Aggregated Forecast", xaxis_title=aggregate_option, yaxis_title=st.session_state['target_col'])

    else:
        if show_trend:
            fig.add_trace(go.Scatter(x=forecast["ds"], y=forecast["yhat"], mode='lines', name='Forecast'))
        if show_bounds:
            fig.add_trace(go.Scatter(x=forecast["ds"], y=forecast["yhat_upper"], mode='lines', name='Upper Bound', line=dict(dash='dot')))
            fig.add_trace(go.Scatter(x=forecast["ds"], y=forecast["yhat_lower"], mode='lines', name='Lower Bound', line=dict(dash='dot')))
        fig.update_layout(title="Forecast with Trend and Confidence Intervals", xaxis_title="Date", yaxis_title=st.session_state['target_col'])

    st.plotly_chart(fig, use_container_width=True)

if section == "YoY Growth" and st.session_state.get("ran_forecast"):
    forecast = st.session_state["forecast"]
    forecast["year"] = forecast["ds"].dt.year
    yearly = forecast.groupby("year")["yhat"].sum().reset_index()
    yearly["YoY Growth %"] = yearly["yhat"].pct_change() * 100

    st.subheader("ðŸ“Š Year-over-Year Growth Analysis")
    model_used = st.session_state.get("selected_model", "Prophet")
    st.info(f"Model Used: {model_used}")
    st.write("This section helps you understand how the forecasted values change from one year to the next.\n\nA positive YoY (Year-over-Year) growth percentage suggests increasing performance, while a negative value indicates decline. This can help in strategic planning and goal setting.")

    show_yoy = st.checkbox("Show YoY % Growth Chart", True)
    show_total = st.checkbox("Show Total Forecast Chart", False)

    col1, col2 = st.columns(2)

    if show_yoy:
        with col1:
            fig1 = px.bar(yearly, x="year", y="YoY Growth %", title="Year-over-Year Growth %")
            st.plotly_chart(fig1, use_container_width=True)

    if show_total:
        with col2:
            fig2 = px.line(yearly, x="year", y="yhat", title="Total Forecast by Year")
            st.plotly_chart(fig2, use_container_width=True)



if section == "Model Explainability" and st.session_state.get("ran_forecast"):
    st.subheader("ðŸ” Model Explainability & Insights")

    model = st.session_state.get("model", None)
    model_used = st.session_state.get("selected_model", None)

    if model_used == "Prophet" and model is not None and hasattr(model, "plot_components"):
        st.write("**Prophet Trend and Seasonality Components**")
        fig_components = model.plot_components()
        st.pyplot(fig_components)

        st.write("**Prophet Changepoints (if any):**")
        try:
            fig_cp = model.plot(model.history, plot_cap=True)
            st.pyplot(fig_cp)
        except Exception:
            st.info("No changepoints plot available.")

    elif model_used == "XGBoost" and model is not None and hasattr(model, "feature_importances_"):
        st.write("**XGBoost Feature Importance**")
        importances = model.feature_importances_
        feature_names = model.get_booster().feature_names
        fi_df = pd.DataFrame({"Feature": feature_names, "Importance": importances})
        fi_df = fi_df.sort_values("Importance", ascending=False)
        st.bar_chart(fi_df.set_index("Feature"))
        st.caption("Higher importance means the feature is more influential in the model's forecast.")

        # Optionally add SHAP global explanation:
        try:
            import shap
            fe_data = st.session_state["fe_data"]
            date_col = st.session_state["date_col"]
            target_col = st.session_state["target_col"]
            df = fe_data.copy()
            df['year'] = df[date_col].dt.year
            df['month'] = df[date_col].dt.month
            df['day'] = df[date_col].dt.day
            df['dayofweek'] = df[date_col].dt.dayofweek
            df['y_lag1'] = df[target_col].shift(1)
            df = df.dropna()
            X = df[['year', 'month', 'day', 'dayofweek', 'y_lag1']]
            explainer = shap.Explainer(model)
            shap_values = explainer(X)
            st.set_option('deprecation.showPyplotGlobalUse', False)
            st.write("**XGBoost SHAP Feature Impact:**")
            st.pyplot(shap.summary_plot(shap_values, X, show=False))
        except Exception as e:
            st.info(f"SHAP summary not available: {e}")

    elif model_used in ["ARIMA", "SARIMA"] and model is not None:
        st.write("**Residual Diagnostics**")
        try:
            import matplotlib.pyplot as plt
            from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

            forecast = st.session_state["forecast"]
            fe_data = st.session_state["fe_data"]
            date_col = st.session_state["date_col"]
            target_col = st.session_state["target_col"]

            actual = fe_data.set_index(date_col)[target_col]
            pred = forecast.set_index("ds")["yhat"]
            actual = actual.loc[actual.index.intersection(pred.index)]
            pred = pred.loc[actual.index]
            residuals = actual - pred

            fig, ax = plt.subplots(2, 2, figsize=(12, 8))
            ax[0,0].plot(residuals.index, residuals.values)
            ax[0,0].set_title("Residuals Over Time")
            ax[0,1].hist(residuals.dropna(), bins=30)
            ax[0,1].set_title("Residuals Histogram")
            plot_acf(residuals.dropna(), ax=ax[1,0], lags=40)
            ax[1,0].set_title("Residuals Autocorrelation")
            plot_pacf(residuals.dropna(), ax=ax[1,1], lags=40)
            ax[1,1].set_title("Residuals Partial Autocorrelation")
            st.pyplot(fig)
            st.caption("Ideally, residuals should look random and centered on zero.")
        except Exception as e:
            st.info(f"Residual diagnostics not available: {e}")

    else:
        st.warning("Model explainability is only available after running a forecast with Prophet, XGBoost, ARIMA, or SARIMA. Please rerun forecast.")




if section == "Advanced Diagnostics" and st.session_state.get("ran_forecast"):
    st.subheader("ðŸ§ª Advanced Diagnostics & Model Quality")

    model_used = st.session_state.get("selected_model", "Prophet")
    st.info(f"Model Used: {model_used}")

    # --- Prophet: Cross-Validation & Performance ---
    if model_used == "Prophet" and "model" in st.session_state and st.session_state["model"] is not None:
        st.write("**Prophet Cross-Validation Performance**")
        from prophet.diagnostics import cross_validation, performance_metrics
        try:
            with st.spinner("Running Prophet cross-validation..."):
                df_cv = cross_validation(st.session_state["model"], initial="365 days", period="180 days", horizon="90 days", parallel="processes")
                df_p = performance_metrics(df_cv)
            st.dataframe(df_p[["horizon", "mse", "rmse", "mae", "mape"]])
            st.line_chart(df_p.set_index("horizon")[["rmse", "mae"]])
        except Exception as e:
            st.warning(f"Prophet cross-validation not available: {e}")

    # --- XGBoost: SHAP Summary Plot ---
    elif model_used == "XGBoost" and "model" in st.session_state and st.session_state["model"] is not None:
        st.write("**XGBoost SHAP Feature Importance (Global Impact)**")
        try:
            import shap
            model = st.session_state["model"]
            # Grab features from your XGBoost train data (ensure same as model.fit)
            fe_data = st.session_state["fe_data"]
            date_col = st.session_state["date_col"]
            target_col = st.session_state["target_col"]
            # Same feature engineering as during XGBoost training
            df = fe_data.copy()
            df['year'] = df[date_col].dt.year
            df['month'] = df[date_col].dt.month
            df['day'] = df[date_col].dt.day
            df['dayofweek'] = df[date_col].dt.dayofweek
            df['y_lag1'] = df[target_col].shift(1)
            df = df.dropna()
            X = df[['year', 'month', 'day', 'dayofweek', 'y_lag1']]
            explainer = shap.Explainer(model)
            shap_values = explainer(X)
            st.set_option('deprecation.showPyplotGlobalUse', False)
            st.pyplot(shap.summary_plot(shap_values, X, show=False))
        except Exception as e:
            st.warning(f"SHAP plot not available: {e}")

    # --- ARIMA/SARIMA: Residual Diagnostics ---
    elif model_used in ["ARIMA", "SARIMA"]:
        st.write("**Residual Diagnostics**")
        try:
            import matplotlib.pyplot as plt
            from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

            forecast = st.session_state["forecast"]
            fe_data = st.session_state["fe_data"]
            date_col = st.session_state["date_col"]
            target_col = st.session_state["target_col"]

            # Align actuals and predictions for in-sample period
            actual = fe_data.set_index(date_col)[target_col]
            pred = forecast.set_index("ds")["yhat"]
            # Make sure indexes align
            actual = actual.loc[actual.index.intersection(pred.index)]
            pred = pred.loc[actual.index]
            residuals = actual - pred

            fig, ax = plt.subplots(2, 2, figsize=(12, 8))
            ax[0,0].plot(residuals.index, residuals.values)
            ax[0,0].set_title("Residuals Over Time")
            ax[0,1].hist(residuals.dropna(), bins=30)
            ax[0,1].set_title("Residuals Histogram")
            plot_acf(residuals.dropna(), ax=ax[1,0], lags=40)
            ax[1,0].set_title("Residuals Autocorrelation")
            plot_pacf(residuals.dropna(), ax=ax[1,1], lags=40)
            ax[1,1].set_title("Residuals Partial Autocorrelation")
            st.pyplot(fig)
            st.caption("Ideally, residuals should look random and centered on zero.")
        except Exception as e:
            st.warning(f"Residual diagnostics not available: {e}")

    else:
        st.info("Run a forecast to see advanced diagnostics.")
elif section == "Advanced Diagnostics":
    st.warning("Please run a forecast first to access advanced diagnostics.")




if section == "Summary Dashboard" and st.session_state.get("ran_forecast"):
    st.subheader("ðŸ“Š Summary Dashboard")
    model_used = st.session_state.get("selected_model", "Prophet")
    st.info(f"Model Used: {model_used}")
    st.write("This dashboard summarizes the key outcomes from the forecast.\n\nYou can quickly view the latest forecast value, total forecasted revenue/sales, and the average YoY growth across years to gain high-level insights.")
    forecast = st.session_state["forecast"]
    latest_forecast = forecast["yhat"].iloc[-1]
    total_forecast = forecast["yhat"].sum()
    yearly = forecast.copy()
    yearly["year"] = yearly["ds"].dt.year
    yoy_df = yearly.groupby("year")["yhat"].sum().pct_change().reset_index()
    avg_yoy = yoy_df["yhat"].mean() * 100

    col1, col2, col3 = st.columns(3)
    col1.metric("Latest Forecast Value", f"{latest_forecast:,.2f}")
    col2.metric("Total Forecast Value", f"{total_forecast:,.2f}")
    col3.metric("Average YoY Growth", f"{avg_yoy:.2f}%")



import tempfile
from fpdf import FPDF
from PIL import Image

if section == "Download Reports" and st.session_state.get("ran_forecast"):
    st.subheader("ðŸ“¥ Download Reports")
    st.write("""
    Download cleaned/feature-engineered/forecasted data in CSV format, chart images in PNG, and both charts together in a PDF report.
    """)

    # -------------------------------
    # 1. Download refined datasets (CSV)
    # -------------------------------
    try:
        cleaned_csv = st.session_state["cleaned_data"].to_csv(index=False).encode('utf-8')
        st.download_button(
            label="ðŸ“„ Download Cleaned Data (CSV)",
            data=cleaned_csv,
            file_name="cleaned_data.csv",
            mime="text/csv"
        )
    except Exception as e:
        st.error(f"Error preparing Cleaned Data CSV: {e}")

    try:
        fe_csv = st.session_state["fe_data"].to_csv(index=False).encode('utf-8')
        st.download_button(
            label="ðŸ“„ Download Feature Engineered Data (CSV)",
            data=fe_csv,
            file_name="feature_engineered_data.csv",
            mime="text/csv"
        )
    except Exception as e:
        st.error(f"Error preparing Feature Engineered Data CSV: {e}")

    try:
        forecast = st.session_state["forecast"]
        slim_forecast = forecast[["ds", "yhat", "yhat_lower", "yhat_upper"]].copy()
        forecast_csv = slim_forecast.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="ðŸ“„ Download Forecast Results (CSV)",
            data=forecast_csv,
            file_name="forecast_results.csv",
            mime="text/csv"
        )
    except Exception as e:
        st.error(f"Error preparing Forecast Results CSV: {e}")

# =============== ADD THIS BLOCK AT THE END ==============
if st.session_state.get("ran_forecast"):
    st.markdown("---")
    st.subheader("Compare Model Errors (Last 30 Actual Points)")

    if st.button("Compare All Models"):
        fe_data = st.session_state.get("fe_data")
        date_col = st.session_state.get("date_col")
        target_col = st.session_state.get("target_col")
        if fe_data is None or date_col is None or target_col is None:
            st.error("Required data missing. Please upload a dataset and run a forecast first.")
        else:
            forecast_data = prepare_dataset(fe_data, date_col, target_col)
            train, test = get_train_test_split(forecast_data, test_size=30)
            models_to_try = [
                ("Prophet", lambda: train_prophet_model(
                    train,
                    seasonality_mode=seasonality_mode,
                    changepoint_prior_scale=changepoint_prior_scale,
                    periods=len(test),
                    return_model=True)),
                ("ARIMA", lambda: train_arima_model(
                    train,
                    order=(arima_p, arima_d, arima_q),
                    forecast_periods=len(test),
                    return_model=True)),
                ("SARIMA", lambda: train_sarima_model(
                    train,
                    order=(sarima_p, sarima_d, sarima_q),
                    seasonal_order=(sarima_P, sarima_D, sarima_Q, sarima_s),
                    forecast_periods=len(test),
                    return_model=True)),
                ("XGBoost", lambda: train_xgb_model(
                    train,
                    forecast_periods=len(test),
                    return_model=True))
                ]

            st.info("Calculating error metrics for all models. This may take a minute...")
            results = []
            for model_name, model_func in models_to_try:
                try:
                    fc = model_func()
                    y_true = test['y'].values
                    if fc.shape[0] > len(y_true):
                        y_pred = fc['yhat'].values[-len(y_true):]
                    else:
                        y_pred = fc['yhat'].values
                    mae = mean_absolute_error(y_true, y_pred)
                    rmse = root_mean_squared_error(y_true, y_pred)
                    mape = mean_absolute_percentage_error(y_true, y_pred)
                    results.append((model_name, mae, rmse, mape))
                except Exception as e:
                    st.warning(f"Model {model_name} failed: {e}")

            if results:
                results_df = pd.DataFrame(results, columns=["Model", "MAE", "RMSE", "MAPE"])
                results_df["MAE"] = results_df["MAE"].round(2)
                results_df["RMSE"] = results_df["RMSE"].round(2)
                results_df["MAPE"] = results_df["MAPE"].round(2)
                st.table(results_df.set_index("Model"))



    # # -------------------------------
    # # 2. Generate and download chart images (PNG)
    # # -------------------------------
    # try:
    #     # Forecast Chart
    #     fig_forecast = px.line(forecast, x="ds", y="yhat", title=f"Forecast for {st.session_state.get('target_col', 'Value')}")
    #     fig_forecast.add_scatter(x=forecast["ds"], y=forecast["yhat_upper"], mode='lines', name='Upper Bound')
    #     fig_forecast.add_scatter(x=forecast["ds"], y=forecast["yhat_lower"], mode='lines', name='Lower Bound')
    #     temp_forecast_img = tempfile.NamedTemporaryFile(suffix=".png", delete=False)
    #     fig_forecast.write_image(temp_forecast_img.name)
    #     with open(temp_forecast_img.name, "rb") as f:
    #         forecast_img_bytes = f.read()

    #     st.subheader("Forecast Chart Image")
    #     st.image(forecast_img_bytes, caption="Forecast Chart", use_column_width=True)
    #     st.download_button(
    #         label="ðŸ“¥ Download Forecast Chart (PNG)",
    #         data=forecast_img_bytes,
    #         file_name="forecast_chart.png",
    #         mime="image/png"
    #     )

    #     # YoY Growth Chart
    #     forecast["year"] = forecast["ds"].dt.year
    #     yearly = forecast.groupby("year")["yhat"].sum().reset_index()
    #     yearly["YoY Growth %"] = yearly["yhat"].pct_change() * 100
    #     yoy_fig = px.bar(yearly, x="year", y="YoY Growth %", title="Year-over-Year Growth")
    #     temp_yoy_img = tempfile.NamedTemporaryFile(suffix=".png", delete=False)
    #     yoy_fig.write_image(temp_yoy_img.name)
    #     with open(temp_yoy_img.name, "rb") as f:
    #         yoy_img_bytes = f.read()

    #     st.subheader("YoY Growth Chart Image")
    #     st.image(yoy_img_bytes, caption="YoY Growth Chart", use_column_width=True)
    #     st.download_button(
    #         label="ðŸ“¥ Download YoY Growth Chart (PNG)",
    #         data=yoy_img_bytes,
    #         file_name="yoy_growth_chart.png",
    #         mime="image/png"
    #     )

    # except Exception as e:
    #     st.error(f"Error generating or displaying chart images: {e}")

    # # -------------------------------
    # # 3. Combine both images into a PDF and download
    # # -------------------------------
    # try:
    #     pdf_tempfile = tempfile.NamedTemporaryFile(suffix=".pdf", delete=False)

    #     # Create a PDF using fpdf
    #     pdf = FPDF()
    #     pdf.set_auto_page_break(auto=True, margin=15)
    #     for img_path in [temp_forecast_img.name, temp_yoy_img.name]:
    #         cover = Image.open(img_path)
    #         width, height = cover.size
    #         # Convert pixel in 1/pt for FPDF (1 pt = 1/72 inch, 1 px = 0.75 pt)
    #         width_pt = width * 0.75
    #         height_pt = height * 0.75
    #         pdf.add_page()
    #         pdf.image(img_path, x=10, y=10, w=width_pt/3, h=height_pt/3) # scaling for A4

    #     pdf.output(pdf_tempfile.name)
    #     with open(pdf_tempfile.name, "rb") as pdf_file:
    #         pdf_bytes = pdf_file.read()

    #     st.subheader("Combined Charts PDF")
    #     st.download_button(
    #         label="ðŸ“¥ Download Both Charts as PDF",
    #         data=pdf_bytes,
    #         file_name="charts_report.pdf",
    #         mime="application/pdf"
    #     )
    # except Exception as e:
    #     st.error(f"Error generating PDF report: {e}")




















#forecasting.py



from prophet import Prophet
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.statespace.sarimax import SARIMAX
import xgboost as xgb
import pandas as pd

def train_prophet_model(data, seasonality_mode='additive', changepoint_prior_scale=0.05, periods=30, return_model=False):
    model = Prophet(seasonality_mode=seasonality_mode, changepoint_prior_scale=changepoint_prior_scale)
    model.fit(data)
    future = model.make_future_dataframe(periods=periods)
    forecast = model.predict(future)
    if return_model:
        return forecast, model
    else:
        return forecast

def train_arima_model(data, order=(1,1,1), forecast_periods=365, return_model=False):
    df = data.copy()
    df = df.groupby('ds', as_index=False).agg({'y': 'sum'})
    df = df.set_index('ds').asfreq('D')
    df['y'].interpolate(inplace=True)
    model = ARIMA(df['y'], order=order)
    model_fit = model.fit()
    forecast = model_fit.forecast(steps=forecast_periods)
    forecast_index = pd.date_range(start=df.index[-1] + pd.Timedelta(days=1), periods=forecast_periods, freq='D')
    forecast_df = pd.DataFrame({'ds': forecast_index, 'yhat': forecast.values})
    forecast_df['yhat_lower'] = forecast_df['yhat'] * 0.95
    forecast_df['yhat_upper'] = forecast_df['yhat'] * 1.05
    if return_model:
        return forecast_df, model_fit
    else:
        return forecast_df

def train_sarima_model(data, order=(1,1,1), seasonal_order=(1,1,1,12), forecast_periods=365, return_model=False):
    df = data.copy()
    df = df.groupby('ds', as_index=False).agg({'y': 'sum'})
    df = df.set_index('ds').asfreq('D')
    df['y'].interpolate(inplace=True)
    model = SARIMAX(df['y'], order=order, seasonal_order=seasonal_order)
    model_fit = model.fit(disp=False)
    forecast = model_fit.forecast(steps=forecast_periods)
    forecast_index = pd.date_range(start=df.index[-1] + pd.Timedelta(days=1), periods=forecast_periods, freq='D')
    forecast_df = pd.DataFrame({'ds': forecast_index, 'yhat': forecast.values})
    forecast_df['yhat_lower'] = forecast_df['yhat'] * 0.95
    forecast_df['yhat_upper'] = forecast_df['yhat'] * 1.05
    if return_model:
        return forecast_df, model_fit
    else:
        return forecast_df

def train_xgb_model(data, forecast_periods=365, return_model=False):
    df = data.copy()
    df['year'] = df['ds'].dt.year
    df['month'] = df['ds'].dt.month
    df['day'] = df['ds'].dt.day
    df['dayofweek'] = df['ds'].dt.dayofweek
    df['y_lag1'] = df['y'].shift(1)
    df = df.dropna()

    X = df[['year', 'month', 'day', 'dayofweek', 'y_lag1']]
    y = df['y']

    model = xgb.XGBRegressor()
    model.fit(X, y)

    last_row = df.iloc[-1]
    future = []
    for i in range(forecast_periods):
        features = {
            'year': last_row['ds'].year,
            'month': last_row['ds'].month,
            'day': last_row['ds'].day + 1,  # This is a simplification; consider using date offsets for production.
            'dayofweek': (last_row['ds'].dayofweek + 1) % 7,
            'y_lag1': last_row['y']
        }
        X_pred = pd.DataFrame([features])
        y_pred = model.predict(X_pred)[0]
        next_date = last_row['ds'] + pd.Timedelta(days=1)
        future.append({'ds': next_date, 'yhat': y_pred})
        last_row = pd.Series({'ds': next_date, 'y': y_pred, **features})

    forecast_df = pd.DataFrame(future)
    forecast_df['yhat_lower'] = forecast_df['yhat'] * 0.95
    forecast_df['yhat_upper'] = forecast_df['yhat'] * 1.05
    if return_model:
        return forecast_df, model
    else:
        return forecast_df

def prepare_dataset(df, date_col, target_col):
    df = df[[date_col, target_col]].copy()
    df = df.rename(columns={date_col: "ds", target_col: "y"})
    df = df.sort_values("ds")
    df = df.dropna()
    df["ds"] = pd.to_datetime(df["ds"])
    df = df[["ds", "y"]]
    return df

def generate_forecast(model, periods=365):
    future = model.make_future_dataframe(periods=periods)
    forecast = model.predict(future)
    return forecast

def get_train_test_split(data, test_size=30):
    train = data.iloc[:-test_size]
    test = data.iloc[-test_size:]
    return train, test

def auto_detect_columns(df):
    # Returns (date_col, target_col)
    date_cols = [col for col in df.columns if pd.api.types.is_datetime64_any_dtype(df[col]) or 'date' in col.lower()]
    num_cols = df.select_dtypes(include='number').columns
    date_col = date_cols[0] if date_cols else df.columns[0]
    target_col = num_cols[0] if len(num_cols) else df.columns[-1]
    return date_col, target_col

